{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62315401",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece,BPE\n",
    "from tokenizers.trainers import WordPieceTrainer, BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68169ba7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls = pd.read_csv('../data/mrconso_eng_strings.csv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300abf1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Sequence, Whitespace, Punctuation, Split\n",
    "\n",
    "whitespace_pretokenizer = Sequence([Whitespace(), Punctuation()])\n",
    " \n",
    "umls_words = {}\n",
    "umls_idf = {}\n",
    "\n",
    "for phrase in tqdm(umls[0]):\n",
    "    \n",
    "    phrase = str(phrase).lower()\n",
    "    \n",
    "    tokens = [t[0] for t in whitespace_pretokenizer.pre_tokenize_str(phrase)]\n",
    "    \n",
    "    for token in tokens:\n",
    "        umls_words[token] = umls_words.get(token,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80c702",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df = pd.DataFrame(umls_words.items())\n",
    "umls_df['word'] = [re.match('^[a-z]+$',w) is not None for w in umls_df[0]]\n",
    "umls_df['len'] = [len(w) for w in umls_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb7474",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df = umls_df[umls_df['len'] > 4].sort_values(1,ascending=False)\n",
    "umls_df = umls_df[umls_df['word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae185ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wiki_words = pickle.load(open('../data/wiki_vocab.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625d743",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pubmed_words = pickle.load(open('../data/words_by_freq.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e93a46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df['wiki_freq'] = [wiki_words[0].get(w,0) for w in umls_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf2304",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df['pubmed_freq'] = [pubmed_words.get(w,0) for w in umls_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a0b4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df['norm_wiki_freq'] = umls_df['wiki_freq']/umls_df['wiki_freq'].sum()\n",
    "umls_df['norm_pubmed_freq'] = umls_df.pubmed_freq/umls_df.pubmed_freq.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c872d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df['norm_pubmedness'] = (umls_df.norm_pubmed_freq - umls_df.norm_wiki_freq)\n",
    "umls_df['pubmedness'] = (umls_df.pubmed_freq - umls_df.wiki_freq)/(umls_df.pubmed_freq + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3392e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df = umls_df[umls_df.norm_pubmedness > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523136ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df['combined_stat'] = umls_df[1]*umls_df.pubmedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab541d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df = umls_df.sort_values('combined_stat',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011add92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df = umls_df[umls_df.len < 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53465690",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_index = None\n",
    "\n",
    "for folder in glob('../output/canine_exps/*'):\n",
    "    results = pickle.load(open('{}/results.p'.format(folder),'rb'))\n",
    "    \n",
    "    max_f1 = np.max([r[0]['overall_f1'] for r in results])\n",
    "    max_f1_ind = np.argmax([r[0]['overall_f1'] for r in results])\n",
    "    \n",
    "    if best_f1 < max_f1:\n",
    "        best_f1 = max_f1\n",
    "        \n",
    "        best_index = (folder, max_f1_ind)\n",
    "\n",
    "best_model = AutoModelForTokenClassification.from_pretrained('{}/best_model'.format(best_index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bdb8a",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_words = tokenize_long_list(umls_df[0],best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653c024",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "umls_df['supervised_tok'] = tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8131b7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e8e58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "split_words = umls_df[umls_df[0] != umls_df.supervised_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe098905",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subword_freq = {}\n",
    "\n",
    "for i,row in tqdm(split_words.iterrows()):\n",
    "\n",
    "    word = row.supervised_tok\n",
    "    freq = row[1]\n",
    "    \n",
    "    subwords = word.split()\n",
    "\n",
    "    for token in subwords:\n",
    "        subword_freq[token] = subword_freq.get(token,0) + freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4c631",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subword_freq_df = pd.DataFrame(subword_freq.items())\n",
    "subword_freq_df['len'] = [len(w.replace('##','')) for w in subword_freq_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb12446",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subword_freq_df.sort_values(1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc94e28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subword_freq_df = subword_freq_df[subword_freq_df[1] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759c271",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chosen_subwords = subword_freq_df\n",
    "chosen_vocab = set(list(chosen_subwords[0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a7f51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(chosen_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fd582",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "letters = set()\n",
    "\n",
    "for token in tqdm(chosen_vocab):\n",
    "    for letter in token:\n",
    "        if letter != '#':\n",
    "            letters.add(letter)\n",
    "            letters.add('##'+letter)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40f0dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chosen_vocab = chosen_vocab.union(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7498d5e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(chosen_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642095a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc051a29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_wordpiece_tokenizer(vocab, tokenizer_save_dir, original_tokenizer='microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract', add_wiki_tokens=False):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(original_tokenizer)\n",
    "    \n",
    "    if add_wiki_tokens:\n",
    "        tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        for token in tokenizer.vocab:\n",
    "            vocab.append(token)\n",
    "    else:\n",
    "        for special in tokenizer.special_tokens_map.values():\n",
    "            if special not in vocab:\n",
    "                vocab.append(special)\n",
    "\n",
    "        for token in tokenizer.vocab:\n",
    "            if len(token.replace('##','')) == 1:\n",
    "                vocab.append(token)\n",
    "            \n",
    "    vocab = list(set(vocab))\n",
    "    \n",
    "    tokenizer.save_pretrained(tokenizer_save_dir)\n",
    "    \n",
    "    tokenizer_config = json.load(open('{}/tokenizer.json'.format(tokenizer_save_dir),'r'))\n",
    "    \n",
    "    with open('{}/vocab.txt'.format(tokenizer_save_dir),'w') as f:\n",
    "        f.writelines([w+'\\n' for w in vocab])\n",
    "        \n",
    "    vocab_dict = {w:i for i,w in enumerate(vocab)}\n",
    "    tokenizer_config['model']['vocab'] = vocab_dict\n",
    "    \n",
    "    json.dump(tokenizer_config, open('{}/tokenizer.json'.format(tokenizer_save_dir),'w'))\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_save_dir)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d4e5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizers = {}\n",
    "\n",
    "biovocabbert = build_wordpiece_tokenizer(list(chosen_vocab), '../output/biovocabbert_tokenizer', add_wiki_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sub-opt",
   "language": "python",
   "name": "sub-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}